{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3zBXM4_xq9zA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Bntmru9DmLN",
    "outputId": "ad67dbf2-5aca-4070-e5bf-396da9909d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\r\n",
    "nltk.download('stopwords')\r\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "u_AqMeyMwrva"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IAgPfhBbrzud"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9T850lBDrzxt"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/content/train_int.csv\")\r\n",
    "traindatat.drop(columns=['id'], inplace=True)\r\n",
    "tesdatant = pd.read_csv(\"/content/test_int.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['review_lenght'] = np.array(list(map(len, X_train_data)))\n",
    "median = train_data['review_lenght'].median()\n",
    "mean = train_data['review_lenght'].mean()\n",
    "mode = train_data['review_lenght'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "R49vK6gi1--5"
   },
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;#]')\r\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z +_]')\r\n",
    "STOPWORDS = set(stopwords.words('english'))\r\n",
    "\r\n",
    "def text_prepare(text):\r\n",
    "    \"\"\"\r\n",
    "        text: a string\r\n",
    "       s return: modified initial string\r\n",
    "    \"\"\"\r\n",
    "    text = text.lower()\r\n",
    "    text = REPLACE_BY_SPACE_RE.sub(\" \", text)\r\n",
    "    text = BAD_SYMBOLS_RE.sub(\"\", text)\r\n",
    "    text = text.split()\r\n",
    "    text = \" \".join([word for word in text if not word in STOPWORDS])\r\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "t7cSdiwF2FZ7"
   },
   "outputs": [],
   "source": [
    "train_int['review'] = train_int['review'].apply(text_prepare)\r\n",
    "test_int['review'] = test_int['review'].apply(text_prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "duycEf1Vrz00"
   },
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_val, X_test):\r\n",
    "    \"\"\"\r\n",
    "        X_train, X_val, X_test â€” samples        \r\n",
    "        return TF-IDF vectorized representation of each sample and vocabulary\r\n",
    "    \"\"\"\r\n",
    "    # Create TF-IDF vectorizer with a proper parameters choice\r\n",
    "    # Fit the vectorizer on the train set\r\n",
    "    # Transform the train, test, and val sets and return the result\r\n",
    "    tfidf_vectorizer = TfidfVectorizer(token_pattern='(\\S+)', min_df=5, max_df=0.9, ngram_range=(1,2))\r\n",
    "    tfidf_vectorizer.fit(X_train)\r\n",
    "    X_train = tfidf_vectorizer.transform(X_train)\r\n",
    "    X_val = tfidf_vectorizer.transform(X_val)\r\n",
    "    X_test = tfidf_vectorizer.transform(X_test)\r\n",
    "    return X_train, X_val, X_test, tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "AOue8Idz3w9N"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(train_int, test_size=0.15)\r\n",
    "X_train = train.review\r\n",
    "X_val = test.review\r\n",
    "X_test = test_int['review']\r\n",
    "y_train = train.sentiment\r\n",
    "y_val = test.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "so6I2s7I3owX"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_val, X_test)\r\n",
    "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5yEdCtTr5d_0"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrleN1fa5uyL",
    "outputId": "a6abe313-696a-4515-f86b-c65d54a51bcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<33644x123875 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4582858 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMnsnCvf5eLh",
    "outputId": "f3ab4e66-60af-4e43-9581-15cec3f37f8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\r\n",
    "classifier.fit(X_train_tfidf,y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "p716XVIo5eTl"
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0EJ1Mnv7jx1",
    "outputId": "86b70fc4-131e-448a-911c-acfab899b724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.9013289036544849\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2631,  259],\n",
       "       [ 335, 2713]])"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix\r\n",
    "print('F1-score: {0}'.format(f1_score(y_pred, y_val.to_numpy())))\r\n",
    "print('Confusion matrix:')\r\n",
    "confusion_matrix(y_pred, y_val.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "0d7agCMf7j3E"
   },
   "outputs": [],
   "source": [
    "y_sub = classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "xaSq7GEc73Ic"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"/content/submission_int.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "F87EvTMt7-QZ"
   },
   "outputs": [],
   "source": [
    "sub[\"sentiment\"] = y_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "HRPhwtX_7-Uh"
   },
   "outputs": [],
   "source": [
    "sub.to_csv('/content/sub4_int.csv', index=False, columns=['id','sentiment'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
